{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/m20163692/anaconda3/envs/tf/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "# Keras fix\n",
    "import tensorflow\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "tensorflow.python.control_flow_ops = control_flow_ops\n",
    "\n",
    "from keras.models import load_model\n",
    "from nl.text_gen import generate_from_model\n",
    "from nl.utils import load_w2v_data, GenerateSamples, print_word_list, parse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n"
     ]
    }
   ],
   "source": [
    "print('Loading files...')\n",
    "\n",
    "text_file = 'text_files/asimov'\n",
    "model_file = 'models/asimov_model.h5'\n",
    "mode = 'general_1'\n",
    "\n",
    "model = load_model(model_file)\n",
    "seq_len = model.input_shape[1]\n",
    "input_dim = model.input_shape[2]\n",
    "\n",
    "word2idx, idx2word, embeddings = load_w2v_data('w2v_embs/asimov/asimov_vocab.json',\n",
    "                                               'w2v_embs/asimov/asimov_embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "SAMPLE 1:\n",
      "— nadie viéndola lo adivinaría. debe de haber sido muy hermosa\n",
      "\n",
      "TRUTH:\n",
      "— nadie viéndola lo adivinaría. debe de haber sido muy hermosa en su juventud. \n",
      " — nunca me lo dijeron, d. g. graciosa, mona, siempre creí que era a lo más que podía aspirar...\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.250000):\n",
      "— nadie viéndola lo adivinaría. debe de haber sido muy hermosa. \n",
      " — ¿y qué? \n",
      " — no, no lo sé. \n",
      " — ¿y qué? \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿qué? \n",
      " — no, no lo sé. \n",
      " — ¿qué? \n",
      " — ¿y qué? \n",
      " — ¿qué? ¿qué? \n",
      " — ¿qué? \n",
      " — no se lo. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿qué? — preguntó seldon.\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.500000):\n",
      "— nadie viéndola lo adivinaría. debe de haber sido muy hermosa en los mundos del espacio. \n",
      " — ¿qué? — preguntó pelorat —. ¿qué, lo que no puedo hacer? ¿qué? \n",
      " — no. \n",
      " — ¿y no es eso lo que me lo ha dicho? \n",
      " — no, no lo sé. \n",
      " — ¿qué? \n",
      " — no lo sé. ¿qué es lo que usted ha hecho? \n",
      " — no, no. \n",
      " — ¿qué? \n",
      " — el doctor fastolfe puede ser un robot, pero en mi opinión,\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.750000):\n",
      "— nadie viéndola lo adivinaría. debe de haber sido muy hermosa, y si « — \n",
      " — ¿qué, señor baley? \n",
      " — hubiera sido el y me gustaría que se me? ¿qué? ¿qué, había y así? \n",
      " demasiado tarde no era así, pero tenía que ser su rostro también, que había sido el miedo, y se había... por más que hay por es y había estado en su pantalla. \n",
      " daneel se puso en pie de su un salto. \n",
      " — ¿quién es? \n",
      " — no puede ser un día muy difícil,\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "SAMPLE 2:\n",
      "— sí, señor. creo que está usted enterado de muchas\n",
      "\n",
      "TRUTH:\n",
      "— sí, señor. creo que está usted enterado de muchas facetas de la tierra y que, en este aspecto, sabe más que yo, porque lleva más tiempo estudiando el tema. \n",
      " — ¿y cómo lo\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.250000):\n",
      "— sí, señor. creo que está usted enterado de muchas cosas. \n",
      " — ¿y qué? \n",
      " — ¿qué? \n",
      " — ¿qué? \n",
      " — ¿qué? \n",
      " — ¿qué? \n",
      " — no. \n",
      " — ¿y qué? \n",
      " — no lo sé. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — no. \n",
      " — ¿qué? \n",
      " — ¿y qué? \n",
      " — no, no. \n",
      " — ¿qué? \n",
      " — no, no lo sé. \n",
      " — ¿y qué? — preguntó seldon. \n",
      " — ¿\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.500000):\n",
      "— sí, señor. creo que está usted enterado de muchas cosas. \n",
      " — ¿y qué? \n",
      " — ¿qué? \n",
      " — no, no lo sé, pero no lo sé. \n",
      " — ¿por qué? \n",
      " — no lo sé. \n",
      " — ¿de qué, si no lo? \n",
      " — ¿qué? — preguntó trevize. \n",
      " — no. ya lo sé. \n",
      " — ¿qué? \n",
      " — no. \n",
      " — ¿y qué? ¿qué? — preguntó seldon. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿qué\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.750000):\n",
      "— sí, señor. creo que está usted enterado de muchas cosas. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿una cosa? ¿y qué? ¿no le parece, a lo que me parece, he de no haber ningún menor — dijo trevize —. por sus la sala de. \n",
      " — ¿y si está usted quien le ha un loco? \n",
      " — sin embargo, es un hombre de la primera fundación, ¿no es así? \n",
      " — si con lo es — dijo el robot —, ¿qué y quiero decir? \n",
      " —\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "SAMPLE 3:\n",
      "— no te pongas nervioso — dijo namarti —. creo que\n",
      "\n",
      "TRUTH:\n",
      "— no te pongas nervioso — dijo namarti —. creo que es lo mejor que has hecho en toda tu vida de aristócrata ocioso. has interpretado el papel que los dioses te habían asignado. de no haber sabido quién\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.250000):\n",
      "— no te pongas nervioso — dijo namarti —. creo que no es más que una vida, pero no es más que una de las que se lo haya dicho. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿qué? \n",
      " — no. \n",
      " — ¿y qué? \n",
      " — no — respondió baley —. no lo sé. \n",
      " — ¿qué? \n",
      " — no. \n",
      " — ¿y qué? \n",
      " — no lo sé. \n",
      " — ¿qué? \n",
      " — ¿qué? \n",
      " — no. \n",
      " — ¿qué? \n",
      " — ¿\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.500000):\n",
      "— no te pongas nervioso — dijo namarti —. creo que no le importa. \n",
      " — ¿qué? \n",
      " — está bien, porque la tierra no es más que un planeta, y que no nos ha en la tierra, ni la más más en la tierra. \n",
      " — ¿qué? \n",
      " — ¿qué? \n",
      " — ¿qué? ¿qué? \n",
      " — ¿y qué? ¿qué? \n",
      " — es lo que me parece, señor baley, pero no es así. \n",
      " — ¿qué? \n",
      " — ¿qué? \n",
      " — ¿qué es?\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.750000):\n",
      "— no te pongas nervioso — dijo namarti —. creo que ya está de la galaxia. se lo he dicho para mí. \n",
      " — ¿y qué? ¿qué? \n",
      " — ya lo sé — dijo —. usted es un usted de la gran fundación, y porque he dado un planeta quizá el planeta, antes de que tal vez haya algo, no te importa que me lo haya hecho, ¿verdad? \n",
      " — no lo sé. \n",
      " — pero si es así, ¿por qué no nos es eso? — preguntó con voz cierto. \n",
      " — no\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Random samples from text_file\n",
    "n_samples = 3\n",
    "n_words = 100\n",
    "print_truth = True\n",
    "n_truth_words = 30\n",
    "temperatures = [0.25, 0.5, 0.75]\n",
    "\n",
    "samples = GenerateSamples(word2idx, text_file, mode, 'dir', n_samples, n_words)\n",
    "\n",
    "for idx, sample in enumerate(samples):\n",
    "    print('-' * 80)\n",
    "    print('SAMPLE %d:' % (idx + 1))\n",
    "    print_word_list(sample[:seq_len])\n",
    "    \n",
    "    if print_truth:\n",
    "        print('\\nTRUTH:')\n",
    "        print_word_list(sample[:seq_len + n_truth_words])\n",
    "    \n",
    "    for temperature in temperatures:\n",
    "        print('\\nGENERATED FROM MODEL (temperature = %f):' % temperature)\n",
    "        model_sample = generate_from_model(sample, model, embeddings, idx2word,\n",
    "                                           word2idx, n_words, temperature, mode=mode)\n",
    "        print_word_list(model_sample)\n",
    "    \n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE TEXT:\n",
      "dentro de un poco mas de un día\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.250000):\n",
      "dentro de un poco mas de un día, un mundo de la tierra, que lo que se había a la tierra no era más que una vida. \n",
      " — ¿y qué? \n",
      " — ¿qué? \n",
      " — no lo sé. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — ¿qué? \n",
      " — no lo sé. \n",
      " — ¿qué? \n",
      " — ¿y qué? \n",
      " — ¿qué? — preguntó seldon. \n",
      " — no. \n",
      " — ¿y qué? \n",
      " —\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.500000):\n",
      "dentro de un poco mas de un día, la que se había a su la tierra, y, por lo tanto, el doctor han fastolfe, no en la tierra. \n",
      " — ¿qué? \n",
      " — es un hombre, una vez, de una gran idea, la más importante. \n",
      " — ¿y por qué no? \n",
      " — el doctor fastolfe está en el hombre en que me parece que no es el único que es la primera fundación. \n",
      " — ¿qué? — preguntó seldon. \n",
      " — no. \n",
      " — ¿por qué?\n",
      "\n",
      "GENERATED FROM MODEL (temperature = 0.750000):\n",
      "dentro de un poco mas de un día, aunque no vida, él no le había que la es más importante. \n",
      " — ¿qué? — preguntó estaba de pie y trevize —. han ido a los mundos no son tan los de los mundos espaciales, forma por lo que los mundos se toda la galaxia más demasiado fuerte y... ¿qué me importa, ¿qué? \n",
      " — « aquí » en la primera « trantor ». \n",
      " — ¿qué? — preguntó baley. \n",
      " — es que yo no me trata de nada, no me\n"
     ]
    }
   ],
   "source": [
    "# Using custom text\n",
    "text = 'dentro de un poco mas de un día'\n",
    "n_words = 100\n",
    "temperatures = [0.25, 0.5, 0.75]\n",
    "\n",
    "print('SOURCE TEXT:\\n%s' % text)\n",
    "\n",
    "for temperature in temperatures:\n",
    "    print('\\nGENERATED FROM MODEL (temperature = %f):' % temperature)\n",
    "    model_sample = generate_from_model(text, model, embeddings, idx2word, word2idx,\n",
    "                                       n_words, temperature, truncating='post',\n",
    "                                       custom_text=True, mode='general_2')\n",
    "    print_word_list(model_sample)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
